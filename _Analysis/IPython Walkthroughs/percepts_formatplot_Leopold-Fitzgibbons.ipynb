{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "lib_path = os.path.abspath(os.path.join('../..','_Libraries'))\n",
    "sys.path.append(lib_path)\n",
    "from rlabs_libutils import DataStruct, select_data, create_outlier_df, find_nearest_above, uniquelist_withidx\n",
    "from rlabs_liblinreg import * # new library for the linear regression functions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from itertools import izip\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read raw data\n",
    "**Note**: a window will apear with which you can select the data, this window can be hidden by the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaid-15.06.11_16.14_jl_nofix_replication_eyetracker_data.txt: eyetracker data (38 colums format)\n",
      "Trial 1 - 1.5 % of data was lost. SNR: 0.928862926542. CV: 1.07658511436\n",
      "Trial 2 - 0.7 % of data was lost. SNR: 0.407201998552. CV: 2.45578362473\n",
      "Trial 3 - 1.3 % of data was lost. SNR: 0.761812301826. CV: 1.31265929626\n",
      "Trial 4 - 2.2 % of data was lost. SNR: 0.823482607092. CV: 1.21435473122\n",
      "Trial 5 - 3.1 % of data was lost. SNR: 0.806924052454. CV: 1.23927400225\n"
     ]
    }
   ],
   "source": [
    "path = select_data()\n",
    "ds = DataStruct(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create outlier DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\pandas\\computation\\expressions.py:21: UserWarning: The installed version of numexpr 1.4.2 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.1\n",
      "\n",
      "  \"version is 2.1\\n\".format(ver=ver), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "outlier_threshold = 100  # velocity values over 100 will be outliers.\n",
    "ambiguousoutlier_th = 80 # velocity values between 80 and 100 will be ambiguous outliers.\n",
    "filter_samples = 5       # the samples following an outlier will not be outliers.\n",
    "\n",
    "df = create_outlier_df(ds,outlier_threshold = outlier_threshold, \n",
    "                      ambiguousoutlier_th = ambiguousoutlier_th, filter_samples = filter_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Compute linear regression of Gaze position between outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outlier_idx = np.where(df['Outlierfiltered'])[0]\n",
    "n = len(outlier_idx)-1\n",
    "lr_struct = []\n",
    "for i in range(n):\n",
    "    lr_struct.append(regressionbtwpoints(df, outlier_idx[i], outlier_idx[i+1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Refine linear regression\n",
    "\n",
    "**method 1:** Using ambiguous outliers\n",
    "\n",
    "**method 2:** Spliting linear regression interval into segments\n",
    "\n",
    "**To do**: weight the linear regression with the number of points used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minintervallen = 50 # minimum interval length (samples)\n",
    "minsamples = 10      # minimum number of samples for a segment of the interval\n",
    "fs = 120.0           # sampling frequency of the tobii eyetracker\n",
    "badfitth = 0.3       # bad fit threshold. a regresison fit with a r_squared value below this, will be refined\n",
    "maxdivisions = 12    # maximum number of divisions to split the bad fits\n",
    "\n",
    "outlier_idx = np.where(df['Outlierfiltered'])[0]\n",
    "n = len(outlier_idx)-1\n",
    "\n",
    "m1_struct = [None]*n\n",
    "\n",
    "for i in range(n):\n",
    "    if lr_struct[i]['r_squared'] < badfitth:\n",
    "\n",
    "        # get bad fit number of samples\n",
    "        nsamples = (df['time'][outlier_idx[i+1]] - df['time'][outlier_idx[i]])/1000.0 * fs\n",
    "        \n",
    "        if nsamples > minintervallen:\n",
    "            itvl_start = outlier_idx[i]\n",
    "            itvl_end = outlier_idx[i+1]\n",
    "            \n",
    "            # method 1: if there are ambiguous outliers within:\n",
    "            amb_outlier_idx = np.where(df['isAmbiguousOutlier'])[0]\n",
    "            rthere = np.sum((amb_outlier_idx >= itvl_start+minsamples)&(amb_outlier_idx <= itvl_end-minsamples))\n",
    "            use_m1 = rthere > 0\n",
    "            if use_m1:\n",
    "                tmp_m1 = method1_useamboutls(df, itvl_start, itvl_end, minsamples)\n",
    "                m1_struct[i] = tmp_m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minintervallen = 50 # minimum interval length (samples)\n",
    "minsamples = 25      # minimum number of samples for a segment of the interval\n",
    "fs = 120.0           # sampling frequency of the tobii eyetracker\n",
    "badfitth = 0.3       # bad fit threshold. a regresison fit with a r_squared value below this, will be refined\n",
    "maxdivisions = 12    # maximum number of divisions to split the bad fits\n",
    "\n",
    "outlier_idx = np.where(df['Outlierfiltered'])[0]\n",
    "n = len(outlier_idx)-1\n",
    "\n",
    "rf_struct1 = [None]*n\n",
    "rf_struct2 = [None]*n\n",
    "rf_bfidx = [None]*n\n",
    "\n",
    "for i in range(n):\n",
    "    if lr_struct[i]['r_squared'] < badfitth:\n",
    "\n",
    "        # get bad fit number of samples\n",
    "        nsamples = (df['time'][outlier_idx[i+1]] - df['time'][outlier_idx[i]])/1000.0 * fs\n",
    "        \n",
    "        if nsamples > minintervallen:\n",
    "            itvl_start = outlier_idx[i]\n",
    "            itvl_end = outlier_idx[i+1]\n",
    "            sgmts1, sgmts2, bfidx = method2_splitintrvl(df, itvl_start, itvl_end, maxdivisions, minsamples, fs = 120.0)\n",
    "            \n",
    "            rf_struct1[i] = sgmts1\n",
    "            rf_struct2[i] = sgmts2\n",
    "            rf_bfidx[i] = bfidx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the best fit from the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# badfit_idx = np.where(r_squared_array < badfitth)[0]\n",
    "badfit_idx = np.where(np.array([fit['r_squared'] for fit in lr_struct]) < badfitth)[0]\n",
    "refinedout = [None] * n\n",
    "\n",
    "for badidx in badfit_idx:\n",
    "    if m1_struct[badidx] != None:           \n",
    "        cumulative_rsqrd_m1 = np.sum(np.power(np.array([item['r_value'] for item in m1_struct[badidx]]),2))\n",
    "        cumulative_rsqrd_m2 = np.sum(np.power(np.array([rf_struct1[badidx][rf_bfidx[badidx]]['r_value'], rf_struct2[badidx][rf_bfidx[badidx]]['r_value']]),2))\n",
    "        \n",
    "        if cumulative_rsqrd_m1 < cumulative_rsqrd_m2:\n",
    "            refinedout.insert(badidx, [rf_struct1[badidx][rf_bfidx[badidx]], rf_struct2[badidx][rf_bfidx[badidx]]])\n",
    "        else:\n",
    "            refinedout.insert(badidx, m1_struct[badidx])\n",
    "            \n",
    "        cumulative_rsqrd_rf = np.sum(np.power(np.array([item['r_value'] for item in refinedout[badidx]]),2))\n",
    "                   \n",
    "    elif rf_struct1[badidx] != None:\n",
    "        refinedout.insert(badidx, [rf_struct1[badidx][rf_bfidx[badidx]], rf_struct2[badidx][rf_bfidx[badidx]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CLASSIFY PERCEPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Create new struct and fill it with good fits of the original linear regression and the best from the refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newlrstruct = []                                  #\n",
    "for i in range(n):                                # for all the outlier-intervals\n",
    "    if i in badfit_idx and refinedout[i] != None: # if it is a bad fit in the original linear regression\n",
    "        for item in refinedout[i]:                #\n",
    "            newlrstruct.append(item)              #\n",
    "    else:                                         # if it was a good fit\n",
    "        newlrstruct.append(lr_struct[i])          #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Define threshold of length of interval, slope and r squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threslen = 30       # minimal segment length\n",
    "thresslo = 0.0007   # slope threshold\n",
    "thresrsq = badfitth # r squared threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - For each fit, compute its percept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fit in newlrstruct:\n",
    "    fit['percept'] = classifyfit(fit)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyfit(fit, threslen = 30, thresslo = 0.0007, thresrsq = 0.3):\n",
    "    \"\"\"\n",
    "        Compute the percept for a given fit.\n",
    "        Three possibilities: A, B, ambiguous\n",
    "        \n",
    "        Input:\n",
    "        - fit: dict containing the result of a linear regression using regressionbtwpoints()\n",
    "        - threslen: minimum interval length. If len(fit) < threslen, percept = ambiguous\n",
    "        - thresslo: minimum slope absolute value.\n",
    "        - thresrsq: minimum r squared value.\n",
    "        \n",
    "        Output:\n",
    "        - percept: 'A', 'B', 'amg'\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # get length of interval in samples:\n",
    "    fit_len = fit['end_idx'] - fit['start_idx']\n",
    "\n",
    "    # condition 1: interval larger than threslen:\n",
    "    c1 = fit_len >= threslen\n",
    "\n",
    "    # condition 2.1: absolute value of slope larger than thresslo:\n",
    "    c21 = np.abs(fit['slope']) > thresslo\n",
    "\n",
    "    # condition 2.2: slope value positive or negative:\n",
    "    c22 = fit['slope'] > 0 # slope<0: A, slope>0: B\n",
    "\n",
    "    # condition 3: r squared higher than thresrsq:\n",
    "    c3 = fit['r_squared'] > thresrsq\n",
    "\n",
    "    # classify percept -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --        \n",
    "    if c1:                                      # is the interval greater than length threshold? YES:\n",
    "        if c21:                                 # is the slope greater than slope threshold? YES:\n",
    "            percept = 'B' if c22 else 'A'       # is the slope positive or negative?\n",
    "        else:                                   # is the slope greater than slope threshold? NO:\n",
    "            percept = 'ambg'                    # ambiguous percept\n",
    "    \n",
    "    else:                                       # is the interval greater than length threshold? NO:\n",
    "        if c3:                                  # is the r squared greater than r squared threshold? YES:\n",
    "            if c21:                             # is the slope greater than slope threshold? YES:\n",
    "                percept = 'B' if c22 else 'A'   # is the slope positive or negative?\n",
    "            else:                               # is the slope greater than slope threshold? NO:\n",
    "                percept = 'ambg'                # ambiguous percept\n",
    "        else:                                   # is the r squared greater than r squared threshold? NO\n",
    "            percept = 'ambg'                    # ambiguous percept\n",
    "            \n",
    "    return percept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# figure 1: a) gaze position with reported and extracted percepts\n",
    "#\t\t\tb) outliers vs no-outliers with reported and extracted percepts\n",
    "a_color = 'gray'\n",
    "b_color = 'lightgray'\n",
    "c_color = 'tomato'\n",
    "\n",
    "f, ax = plt.subplots(1, sharex = True)\n",
    "\n",
    "ax.plot(df['time'], df['LEpos_int'], label = 'leftgazeX (interpolated)') \t\t\t\t\t\t\t\t\t\t\t\t# velocity\n",
    "ax.set_title('Position trace (degrees)')\n",
    "\n",
    "for event in ds.trial_ts:\n",
    "    ax.plot((event, event), (np.min(df['LEpos_int']),np.max(df['LEpos_int'])), 'k-')\t\t\t\t\t\t\t\t# line to indicate start and end of trial\n",
    "for on, off in ds.A_ts:\n",
    "    ax.axvspan(on, off, ymin=0.5, ymax=0.99, facecolor=a_color, linewidth=0, alpha=0.5, label = 'A percept') \t\t\t# reported percepts for a (button press)\n",
    "for on, off in ds.B_ts:\n",
    "    ax.axvspan(on, off, ymin=0.5, ymax=0.99, facecolor=b_color, linewidth=0, alpha=0.5, label = 'B percept') \t\t\t# reported percepts for b\n",
    "\n",
    "for fit in newlrstruct:\n",
    "    on  = fit['start']\n",
    "    off = fit['end']\n",
    "    \n",
    "    if fit['percept'] == 'A':\n",
    "        pltcolor = a_color\n",
    "        label = 'A percept'\n",
    "    elif fit['percept'] == 'B':\n",
    "        pltcolor = b_color\n",
    "        label = 'B percept'\n",
    "    else:\n",
    "        pltcolor = c_color\n",
    "        pltlabel = 'ambg percept'\n",
    "    \n",
    "    ax.axvspan(on, off, ymin=0.01, ymax=.5, facecolor=pltcolor, linewidth=0, alpha=0.5, label = pltlabel)\n",
    "\n",
    "ax.set_ylabel(\"Extracted percepts | Reported percepts\")\n",
    "\n",
    "\n",
    "# Get artists and labels for legend of first subplot\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labelsidx, labels = uniquelist_withidx(labels)\n",
    "ax.legend([handles[idx] for idx in labelsidx], labels)\n",
    "ax.set_xlabel('time (ms)')\n",
    "\n",
    "f.suptitle(ds.filename.split()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
