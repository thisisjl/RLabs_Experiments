{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "lib_path = os.path.abspath(os.path.join('..','_Libraries'))\n",
    "sys.path.append(lib_path)\n",
    "from rlabs_libutils import DataStruct, select_data, create_outlier_df, find_nearest_above\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from itertools import izip\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read raw data\n",
    "**Note**: a window will apear with which you can select the data, this window can be hidden by the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaid-15.06.11_16.14_jl_nofix_replication_eyetracker_data.txt: eyetracker data (38 colums format)\n",
      "Trial 1 - 1.5 % of data was lost. SNR: 0.928862926542. CV: 1.07658511436\n",
      "Trial 2 - 0.7 % of data was lost. SNR: 0.407201998552. CV: 2.45578362473\n",
      "Trial 3 - 1.3 % of data was lost. SNR: 0.761812301826. CV: 1.31265929626\n",
      "Trial 4 - 2.2 % of data was lost. SNR: 0.823482607092. CV: 1.21435473122\n",
      "Trial 5 - 3.1 % of data was lost. SNR: 0.806924052454. CV: 1.23927400225\n"
     ]
    }
   ],
   "source": [
    "path = select_data()\n",
    "ds = DataStruct(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create outlier DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outlier_threshold = 100  # velocity values over 100 will be outliers.\n",
    "ambiguousoutlier_th = 80 # velocity values between 80 and 100 will be ambiguous outliers.\n",
    "filter_samples = 5       # the samples following an outlier will not be outliers.\n",
    "\n",
    "df = create_outlier_df(ds,outlier_threshold = outlier_threshold, \n",
    "                      ambiguousoutlier_th = ambiguousoutlier_th, filter_samples = filter_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Compute linear regression of Gaze position between outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outlier_idx = np.where(df['Outlierfiltered'])[0]\n",
    "slope_array = []\n",
    "intercept_array = []\n",
    "r_value_array = []\n",
    "n = len(outlier_idx)-1\n",
    "for i in range(n):\n",
    "    lr_idx = np.arange(outlier_idx[i],outlier_idx[i+1])   # linear regression idx. outlier and next outlier\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(df['time'][lr_idx], df['LEpos_int'][lr_idx])\n",
    "    \n",
    "    slope_array.append(slope)\n",
    "    intercept_array.append(intercept)\n",
    "    r_value_array.append(r_value)\n",
    "    \n",
    "r_squared_array = np.power(r_value_array,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Plot: \n",
    "a) gaze position with linear regression\n",
    "\n",
    "b) velocity with outliers and ambiguous outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, sharex = True)\n",
    "ax[0].plot(df['time'], df['LEpos_int'])\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    ax[0].plot(df['time'][outlier_idx[i:i+2]], slope_array[i]*df['time'][outlier_idx[i:i+2]] + intercept_array[i], 'r')\n",
    "\n",
    "    # compute annotation coordinates\n",
    "    x = df['time'][outlier_idx[i]] + np.diff(df['time'][outlier_idx[i:i+2]])[0]/2.0\n",
    "    y = np.diff(slope_array[i]*df['time'][outlier_idx[i:i+2]] + intercept_array[i])[0]/2.0\n",
    "    ax[0].annotate('{0}'.format(\"%.2f\" % r_squared_array[i]), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "ax[1].plot(df['time'], df['velocity'])\n",
    "ax[1].scatter(df['time'][df['Outlierfiltered']], df['velocity'][df['Outlierfiltered']],color ='r')\n",
    "ax[1].scatter(df['time'][df['isAmbiguousOutlier']], df['velocity'][df['isAmbiguousOutlier']],color ='y')\n",
    "\n",
    "f.suptitle(ds.filename)\n",
    "ax[0].set_title('eye gaze with linear regression and r squared values')\n",
    "ax[1].set_title('velocity with outliers. outlier threshold = {0}'.format(outlier_threshold))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Refine linear regression\n",
    "\n",
    "**method 1:** Using ambiguous outliers\n",
    "\n",
    "**method 2:** Spliting linear regression interval into segments\n",
    "\n",
    "*General note*: the functions are defined first, scroll down to use each method.\n",
    "\n",
    "**To do**: weight the linear regression with the number of points used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regressionbtwpoints(df, start, end, xlabel = 'time', ylabel = 'LEpos_int'):\n",
    "    \"\"\"\n",
    "        Compute the linear regression of df between start and end points.\n",
    "        \n",
    "        Input:\n",
    "        - df: Pandas.DataFrame containing eyetracker data\n",
    "        - start: starting point for the linear regression\n",
    "        - end: ending point for the linear regression\n",
    "        - xlabel: df data to use as horizontal axis of the linear regression. Default as 'time'\n",
    "        - ylabel: df data to use as vertical axis of the linear regression. Default as 'LEpos_int'\n",
    "\n",
    "        Output:\n",
    "        - tmp: dictionary containing linear regression results\n",
    "\n",
    "    \"\"\"\n",
    "    lr_idx = np.arange(start, end)                                                                                  # indices array\n",
    "\n",
    "    # compute linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(df[xlabel][lr_idx], df[ylabel][lr_idx])\n",
    "\n",
    "    # add results to temporal struct\n",
    "    tmp = {'start':df['time'][start], 'end': df['time'][end], 'start_idx': start, 'end_idx':end,\n",
    "                 'slope':slope, 'intercept': intercept, 'r_value': r_value, 'p_value': p_value, 'std_err': std_err}\n",
    "\n",
    "    return tmp\n",
    "\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
    "\n",
    "def method1_useamboutls(df, itvl_start, itvl_end, btwpoints):\n",
    "    \"\"\"\n",
    "        Refinement method 1: Using ambiguous outliers.\n",
    "\n",
    "        Input:\n",
    "        - df: data frame\n",
    "        - itvl_start: interval start (first outlier)\n",
    "        - itvl_end: interval end (second outlier)\n",
    "        - btwpoints: samples between points (threshold)\n",
    "        \n",
    "        Output:\n",
    "        - m1_struct: list of dictionaries containing the regression data.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the indices of the ambiguous outliers in the interval\n",
    "    amb_outlier_idx = np.where(df['isAmbiguousOutlier'])[0]\n",
    "    amb_btwn_outlrs = amb_outlier_idx[(np.where((amb_outlier_idx >= itvl_start+btwpoints) & (amb_outlier_idx <= itvl_end-btwpoints)))]\n",
    "    \n",
    "    # get the ambiguous outliers that are separated by btwpoints samples\n",
    "    nwlridx = [amb_btwn_outlrs[0]] # always use first ambiguous outlier\n",
    "    for item in amb_btwn_outlrs: # for all the points\n",
    "        if item > (nwlridx[-1]+btwpoints): # if point is greater than last point in nwlridx,\n",
    "            nwlridx.append(item) # get it\n",
    "    nwlridx.insert(0,itvl_start)                    # prepend interval start\n",
    "    nwlridx.insert(len(nwlridx),itvl_end)           # append interval end\n",
    "    \n",
    "    m1_struct = []                                  # define struct with regression data\n",
    "\n",
    "    for j in range(len(nwlridx)-1):                         # for all the points\n",
    "        sgm_start = nwlridx[j]                              # get the segment start\n",
    "        sgm_end = nwlridx[j+1]                              # get the segment end\n",
    "        tmp = regressionbtwpoints(df, sgm_start, sgm_end)   # compute linear regression\n",
    "        m1_struct.append(tmp)                               # append results to struct\n",
    "        \n",
    "    return m1_struct\n",
    "\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
    "\n",
    "def method2_splitintrvl(df, itvl_start, itvl_end, maxdivisions, minsamples, fs = 120.0):\n",
    "    \"\"\"\n",
    "        Refinement method 2: split interval in segments\n",
    "\n",
    "        Input:\n",
    "        - df: data frame\n",
    "        - itvl_start: interval start (first outlier)\n",
    "        - itvl_end: interval end (second outlier)\n",
    "        - maxdivisions: maximum number of divisions allowed\n",
    "        - minsamples: minimum number of samples in a segment\n",
    "        - fs: sampling frequency of the data (120 Hz for Tobii X120)\n",
    "\n",
    "        Output:\n",
    "        - m2_struct1: list of dictionaries containing the regression data of the left segments.\n",
    "        - m2_struct2: list of dictionaries containing the regression data of the right segments.\n",
    "    \"\"\"\n",
    "\n",
    "    bfdur = df['time'][itvl_end] - df['time'][itvl_start]                   # get bad fit duration\n",
    "\n",
    "    nsamples = bfdur/1000.0 * fs                                            # number of samples in segment\n",
    "\n",
    "    while (nsamples / maxdivisions) < minsamples:                           # if shortest segment is shorter than minsamples, \n",
    "        maxdivisions -= 1                                                   # decrease number of divisions\n",
    "    \n",
    "    m2_struct1 = []                                                         # define struct that will contain regression data\n",
    "    m2_struct2 = []                                                         # define struct that will contain regression data\n",
    "    for it in range(1, maxdivisions):\n",
    "        \n",
    "        # segment 1 -----------------------------------------------------------------------------------------------------------\n",
    "        # start and end indices segment 1\n",
    "        s1_start = itvl_start                                               # segment 1 always starts where interval starts\n",
    "        end   = df['time'][s1_start] + it * (bfdur / maxdivisions)          # end of segment 1 in seconds\n",
    "        _, s1_end = find_nearest_above(df['time'].values, end)              # index of the end of segment 1\n",
    "\n",
    "        tmp1 = regressionbtwpoints(df, s1_start, s1_end)                    # compute linear regression\n",
    "\n",
    "        # segment 2 ----------------------------------------------------------------------------------------------------------\n",
    "        # start and end indices segment 1\n",
    "        s2_start = s1_end\n",
    "        s2_end = itvl_end\n",
    "\n",
    "        tmp2 = regressionbtwpoints(df, s2_start, s2_end)                        # compute linear regression\n",
    "        \n",
    "        # append to structs\n",
    "        m2_struct1.append(tmp1)\n",
    "        m2_struct2.append(tmp2)\n",
    "\n",
    "    # get best fit index\n",
    "    bestfit = getbestjointfit(m2_struct1, m2_struct2)\n",
    "\n",
    "\n",
    "    return m2_struct1, m2_struct2, bestfit\n",
    "\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
    "\n",
    "def getbestjointfit(segm1, segm2):\n",
    "    \"\"\"\n",
    "        Sum the r squared value of each corresponding segment\n",
    "        and return the index of the maximum.\n",
    "        \n",
    "        Input:\n",
    "            - segm1, segm2: element of refined linear regression struct. (not rf_struct1, but rf_struct[i])\n",
    "        Output:\n",
    "            - max_idx: the index where the refinement segments have the greater joint r squared value.\n",
    "    \"\"\"\n",
    "    \n",
    "    r_squared1 = np.power(np.array([item['r_value'] for item in segm1]),2)\n",
    "    r_squared2 = np.power(np.array([item['r_value'] for item in segm2]),2)\n",
    "\n",
    "    joint_rsquared = r_squared1 + r_squared2\n",
    "    max_idx = np.where(joint_rsquared == np.max(joint_rsquared))[0]\n",
    "   \n",
    "    return max_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minintervallen = 50 # minimum interval length (samples)\n",
    "minsamples = 10      # minimum number of samples for a segment of the interval\n",
    "fs = 120.0           # sampling frequency of the tobii eyetracker\n",
    "badfitth = 0.3       # bad fit threshold. a regresison fit with a r_squared value below this, will be refined\n",
    "maxdivisions = 12    # maximum number of divisions to split the bad fits\n",
    "\n",
    "outlier_idx = np.where(df['Outlierfiltered'])[0]\n",
    "n = len(outlier_idx)-1\n",
    "\n",
    "rf_struct1 = []\n",
    "rf_struct2 = []\n",
    "rf_bfidx = []\n",
    "\n",
    "m1_struct = []\n",
    "\n",
    "for i in range(n):\n",
    "    if r_squared_array[i] < badfitth:\n",
    "\n",
    "        # get bad fit number of samples\n",
    "        nsamples = (df['time'][outlier_idx[i+1]] - df['time'][outlier_idx[i]])/1000.0 * fs\n",
    "        \n",
    "        if nsamples > minintervallen:\n",
    "            itvl_start = outlier_idx[i]\n",
    "            itvl_end = outlier_idx[i+1]\n",
    "            \n",
    "            # method 1: if there are ambiguous outliers within:\n",
    "            amb_outlier_idx = np.where(df['isAmbiguousOutlier'])[0]\n",
    "            rthere = np.sum((amb_outlier_idx >= itvl_start+minsamples)&(amb_outlier_idx <= itvl_end-minsamples))\n",
    "            use_m1 = rthere > 0\n",
    "            if use_m1:\n",
    "                tmp_m1 = method1_useamboutls(df, itvl_start, itvl_end, minsamples)\n",
    "                m1_struct.append(tmp_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot method 1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, sharex = True)\n",
    "ax[0].plot(df['time'], df['LEpos_int'])  # plot gaze\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    # plot linear regression\n",
    "    ax[0].plot(df['time'][outlier_idx[i:i+2]], slope_array[i]*df['time'][outlier_idx[i:i+2]] + intercept_array[i], 'r')\n",
    "    \n",
    "    # compute annotation coordinates\n",
    "    x = df['time'][outlier_idx[i]] + np.diff(df['time'][outlier_idx[i:i+2]])[0]/2.0\n",
    "    y = np.diff(slope_array[i]*df['time'][outlier_idx[i:i+2]] + intercept_array[i])[0]/2.0\n",
    "    ax[0].annotate('{0}'.format(\"%.2f\" % r_squared_array[i]), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "\n",
    "# plot refined linear regression --------------------------------------------------------------------------------------------\n",
    "for fit in (m1_struct):\n",
    "    for j in range(len(fit)):\n",
    "        a = fit[j]\n",
    "        axaxis = np.array([a['start'],a['end']])\n",
    "        ax[0].plot(axaxis, a['slope']*axaxis + a['intercept'], 'y')\n",
    "\n",
    "        # compute annotation coordinates\n",
    "        x = axaxis[0] + np.diff(axaxis)[0]/2.0\n",
    "        y = np.diff(a['slope']*axaxis + a['intercept'])[0]/2.0 + 2\n",
    "        ax[0].annotate('{0}'.format(\"%.2f\" % a['r_value']**2), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "ax[1].plot(df['time'], df['velocity'])\n",
    "ax[1].scatter(df['time'][df['Outlierfiltered']], df['velocity'][df['Outlierfiltered']],color ='r')\n",
    "ax[1].scatter(df['time'][df['isAmbiguousOutlier']], df['velocity'][df['isAmbiguousOutlier']],color ='y')\n",
    "\n",
    "f.suptitle(ds.filename)\n",
    "ax[0].set_title('eye gaze with linear regression and r squared values')\n",
    "ax[1].set_title('velocity with outliers. outlier threshold = {0}'.format(outlier_threshold))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Use method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minintervallen = 50 # minimum interval length (samples)\n",
    "minsamples = 25      # minimum number of samples for a segment of the interval\n",
    "fs = 120.0           # sampling frequency of the tobii eyetracker\n",
    "badfitth = 0.3       # bad fit threshold. a regresison fit with a r_squared value below this, will be refined\n",
    "maxdivisions = 12    # maximum number of divisions to split the bad fits\n",
    "\n",
    "outlier_idx = np.where(df['Outlierfiltered'])[0]\n",
    "n = len(outlier_idx)-1\n",
    "\n",
    "rf_struct1 = []\n",
    "rf_struct2 = []\n",
    "rf_bfidx = []\n",
    "\n",
    "for i in range(n):\n",
    "    if r_squared_array[i] < badfitth:\n",
    "\n",
    "        # get bad fit number of samples\n",
    "        nsamples = (df['time'][outlier_idx[i+1]] - df['time'][outlier_idx[i]])/1000.0 * fs\n",
    "        \n",
    "        if nsamples > minintervallen:\n",
    "            itvl_start = outlier_idx[i]\n",
    "            itvl_end = outlier_idx[i+1]\n",
    "            sgmts1, sgmts2, bfidx = method2_splitintrvl(df, itvl_start, itvl_end, maxdivisions, minsamples, fs = 120.0)\n",
    "            \n",
    "            rf_struct1.append(sgmts1)\n",
    "            rf_struct2.append(sgmts2)\n",
    "            rf_bfidx.append(bfidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, sharex = True)\n",
    "ax[0].plot(df['time'], df['LEpos_int'])  # plot gaze\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    # plot linear regression\n",
    "    ax[0].plot(df['time'][outlier_idx[i:i+2]], slope_array[i]*df['time'][outlier_idx[i:i+2]] + intercept_array[i], 'r')\n",
    "    \n",
    "    # compute annotation coordinates\n",
    "    x = df['time'][outlier_idx[i]] + np.diff(df['time'][outlier_idx[i:i+2]])[0]/2.0\n",
    "    y = np.diff(slope_array[i]*df['time'][outlier_idx[i:i+2]] + intercept_array[i])[0]/2.0\n",
    "    ax[0].annotate('{0}'.format(\"%.2f\" % r_squared_array[i]), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "\n",
    "# plot refined linear regression --------------------------------------------------------------------------------------------\n",
    "\n",
    "for i in range(len(rf_struct1)):\n",
    "    a = rf_struct1[i][rf_bfidx[i]]\n",
    "\n",
    "    axaxis = np.array([a['start'],a['end']])\n",
    "    ax[0].plot(axaxis, a['slope']*axaxis + a['intercept'], 'y')\n",
    "\n",
    "    # compute annotation coordinates\n",
    "    x = axaxis[0] + np.diff(axaxis)[0]/2.0\n",
    "    y = np.diff(a['slope']*axaxis + a['intercept'])[0]/2.0 + 2\n",
    "    ax[0].annotate('{0}'.format(\"%.2f\" % a['r_value']**2), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "    ax[0].plot([a['end'],a['end']], [-np.mean(df['LEpos_int']), np.mean(df['LEpos_int'])], 'y')\n",
    "\n",
    "for i in range(len(rf_struct2)):\n",
    "    a = rf_struct2[i][rf_bfidx[i]]\n",
    "\n",
    "    axaxis = np.array([a['start'],a['end']])\n",
    "    ax[0].plot(axaxis, a['slope']*axaxis + a['intercept'], 'y')\n",
    "\n",
    "    # compute annotation coordinates\n",
    "    x = axaxis[0] + np.diff(axaxis)[0]/2.0\n",
    "    y = np.diff(a['slope']*axaxis + a['intercept'])[0]/2.0 + 2\n",
    "    ax[0].annotate('{0}'.format(\"%.2f\" % a['r_value']**2), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "ax[1].plot(df['time'], df['velocity'])\n",
    "ax[1].scatter(df['time'][df['Outlierfiltered']], df['velocity'][df['Outlierfiltered']],color ='r')\n",
    "ax[1].scatter(df['time'][df['isAmbiguousOutlier']], df['velocity'][df['isAmbiguousOutlier']],color ='y')\n",
    "\n",
    "f.suptitle(ds.filename)\n",
    "ax[0].set_title('eye gaze with linear regression and r squared values')\n",
    "ax[1].set_title('velocity with outliers. outlier threshold = {0}'.format(outlier_threshold))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot both methods together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, sharex = True)\n",
    "ax[0].plot(df['time'], df['LEpos_int'])  # plot gaze\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    # plot linear regression\n",
    "    ax[0].plot(df['time'][outlier_idx[i:i+2]], slope_array[i]*df['time'][outlier_idx[i:i+2]] + intercept_array[i], 'r')\n",
    "    \n",
    "    # compute annotation coordinates\n",
    "    x = df['time'][outlier_idx[i]] + np.diff(df['time'][outlier_idx[i:i+2]])[0]/2.0\n",
    "    y = np.diff(slope_array[i]*df['time'][outlier_idx[i:i+2]] + intercept_array[i])[0]/2.0\n",
    "    ax[0].annotate('{0}'.format(\"%.2f\" % r_squared_array[i]), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "# METHOD 1 --------------------------------------------------------------------------------------------\n",
    "for fit in (m1_struct):\n",
    "    for j in range(len(fit)):\n",
    "        a = fit[j]\n",
    "        axaxis = np.array([a['start'],a['end']])\n",
    "        ax[0].plot(axaxis, a['slope']*axaxis + a['intercept'], 'g')\n",
    "\n",
    "        # compute annotation coordinates\n",
    "        x = axaxis[0] + np.diff(axaxis)[0]/2.0\n",
    "        y = np.diff(a['slope']*axaxis + a['intercept'])[0]/2.0 + 2\n",
    "        ax[0].annotate('{0}'.format(\"%.2f\" % a['r_value']**2), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "        \n",
    "        ax[0].plot([a['end'],a['end']], [-2*np.mean(df['LEpos_int']), 2*np.mean(df['LEpos_int'])], 'm')\n",
    "    \n",
    "# METHOD 2 --------------------------------------------------------------------------------------------\n",
    "\n",
    "for i in range(len(rf_struct1)):\n",
    "    a = rf_struct1[i][rf_bfidx[i]]\n",
    "\n",
    "    axaxis = np.array([a['start'],a['end']])\n",
    "    ax[0].plot(axaxis, a['slope']*axaxis + a['intercept'], 'y')\n",
    "\n",
    "    # compute annotation coordinates\n",
    "    x = axaxis[0] + np.diff(axaxis)[0]/2.0\n",
    "    y = np.diff(a['slope']*axaxis + a['intercept'])[0]/2.0 + 2\n",
    "    ax[0].annotate('{0}'.format(\"%.2f\" % a['r_value']**2), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "    ax[0].plot([a['end'],a['end']], [-np.mean(df['LEpos_int']), np.mean(df['LEpos_int'])], 'y')\n",
    "\n",
    "for i in range(len(rf_struct2)):\n",
    "    a = rf_struct2[i][rf_bfidx[i]]\n",
    "\n",
    "    axaxis = np.array([a['start'],a['end']])\n",
    "    ax[0].plot(axaxis, a['slope']*axaxis + a['intercept'], 'y')\n",
    "\n",
    "    # compute annotation coordinates\n",
    "    x = axaxis[0] + np.diff(axaxis)[0]/2.0\n",
    "    y = np.diff(a['slope']*axaxis + a['intercept'])[0]/2.0 + 2\n",
    "    ax[0].annotate('{0}'.format(\"%.2f\" % a['r_value']**2), xy=(x,y), horizontalalignment='center', verticalalignment='bottom')\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "ax[1].plot(df['time'], df['velocity'])\n",
    "ax[1].scatter(df['time'][df['Outlierfiltered']], df['velocity'][df['Outlierfiltered']],color ='r')\n",
    "ax[1].scatter(df['time'][df['isAmbiguousOutlier']], df['velocity'][df['isAmbiguousOutlier']],color ='y')\n",
    "\n",
    "f.suptitle(ds.filename)\n",
    "ax[0].set_title('eye gaze with linear regression and r squared values')\n",
    "ax[1].set_title('velocity with outliers. outlier threshold = {0}'.format(outlier_threshold))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of linear regression intervals with a r_squared < 0.3:\t1079\n",
      "Number of intervals refined with ambiguous outliers: \t98\n",
      "Number of intervals refined with splitting window: \t125\n"
     ]
    }
   ],
   "source": [
    "print 'Number of linear regression intervals with a r_squared < 0.3:\\t{2}\\nNumber of intervals refined with ambiguous outliers: \\t{1}\\nNumber of intervals refined with splitting window: \\t{0}'.format(\n",
    "    len(rf_struct2), len(m1_struct),np.sum((r_squared_array < badfitth)!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-131-a35b8409788e>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-131-a35b8409788e>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "badfit_idx = np.where(r_squared_array < badfitth)[0]\n",
    "\n",
    "for bfidx in badfit_idx:\n",
    "#     r_squared_array[bfidx]\n",
    "    print bfidx, outlier_idx[bfidx],outlier_idx[bfidx+1]\n",
    "    \n",
    "    print m1_struct[]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
